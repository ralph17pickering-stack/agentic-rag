# Module 4: Metadata Extraction

**Complexity:** ⚠️ **Medium** — Changes across DB, 4 backend files, 2 frontend files. Single-pass feasible.

## Context

Documents are stored with only filename and file size. There's no title, summary, topic tagging, or date information. Retrieval is pure cosine similarity with no date awareness. The chat context contains only raw chunk content and similarity scores.

This module adds LLM-extracted metadata during ingestion, date-aware retrieval (filtering + recency boost), and richer display in the documents panel and retrieval context.

---

## Task 1: Database Migration

**File:** `supabase/migrations/004_metadata_extraction.sql`

```sql
ALTER TABLE documents ADD COLUMN title TEXT;
ALTER TABLE documents ADD COLUMN summary TEXT;
ALTER TABLE documents ADD COLUMN topics TEXT[] DEFAULT '{}';
ALTER TABLE documents ADD COLUMN document_date DATE;
```

Replace `match_chunks` function to:
- JOIN with `documents` to return `doc_title`, `doc_topics`, `doc_date`
- Accept optional `filter_date_from DATE`, `filter_date_to DATE` for filtering (with `created_at::date` fallback for NULL `document_date`)
- Accept `recency_weight FLOAT DEFAULT 0.0` — when > 0 and `document_date` is not null, blend: `(1 - w) * similarity + w * (1 / (1 + days_old / 365))`
- Default `recency_weight = 0.0` preserves existing behavior

**Verify:** Confirm new columns on documents table, `\df match_chunks` shows new parameter signature.

---

## Task 2: Metadata Extraction Service

**File:** `app/backapp/frontend/app/services/metadata.py` (new)

Pydantic model:
```python
class DocumentMetadata(BaseModel):
    title: str
    summary: str
    topics: list[str]
    document_date: date | None
```

`extract_metadata(text: str) -> DocumentMetadata`:
- Truncate to first 2000 tokens (reuse `encoding` from `chunker.py`)
- Call LLM with `response_format={"type": "json_object"}` and extraction prompt
- Parse response with `DocumentMetadata.model_validate_json()`
- Graceful fallback on failure: title = first line, empty summary/topics, no date
- Decorated with `@traceable`
- Reuse `client` from `llm.py` (already LangSmith-wrapped)

---

## Task 3: Update Ingestion Pipeline

**File:** `app/backapp/frontend/app/services/ingestion.py`

After downloading and decoding text, before chunking:
1. `metadata = await extract_metadata(text)`
2. When updating document to "ready", include metadata fields:
   ```python
   {"status": "ready", "chunk_count": len(chunks),
    "title": metadata.title, "summary": metadata.summary,
    "topics": metadata.topics,
    "document_date": metadata.document_date.isoformat() if metadata.document_date else None}
   ```

---

## Task 4: Update Pydantic Document Model

**File:** `app/backapp/frontend/app/models/documents.py`

Add to `DocumentResponse`:
- `title: str | None = None`
- `summary: str | None = None`
- `topics: list[str] = []`
- `document_date: str | None = None`

---

## Task 5: Update Retrieval Service

**File:** `app/backapp/frontend/app/services/retrieval.py`

Add optional params to `retrieve_chunks()`:
- `date_from: str | None = None`
- `date_to: str | None = None`
- `recency_weight: float = 0.0`

Pass all through to `match_chunks` RPC. Returned dicts now include `doc_title`, `doc_topics`, `doc_date`.

---

## Task 6: Update Tool Definition and Context Format

**File:** `app/backapp/frontend/app/services/llm.py`

**6a — Update `TOOLS`:** Add optional `date_from` (string, YYYY-MM-DD), `date_to` (string), `recency_weight` (number 0-1) to `retrieve_documents` tool parameters.

**6b — Update `RetrieveFn`:** Change type to accept `**kwargs`:
```python
RetrieveFn = Callable[..., Awaitable[list[dict]]]
```

**6c — Update tool call handling:** Parse `date_from`, `date_to`, `recency_weight` from args, pass as kwargs to `retrieve_fn`.

**6d — Enrich context format:** Include doc metadata in chunk headers:
```
[Chunk 1] (from: <title>) [date: 2024-03-15] [topics: finance, quarterly] (score: 0.85)
<content>
```

---

## Task 7: Update Chat Router

**File:** `app/backapp/frontend/app/routers/chat.py`

Change `retrieve_fn` closure to accept and forward kwargs:
```python
async def retrieve_fn(query: str, **kwargs) -> list[dict]:
    return await retrieve_chunks(query, user_token, **kwargs)
```

---

## Task 8: Update Frontend Types

**File:** `app/frontend/src/types/index.ts`

Add to `Document`:
- `title: string | null`
- `summary: string | null`
- `topics: string[]`
- `document_date: string | null`

---

## Task 9: Update DocumentsPanel UI

**File:** `app/frontend/src/components/documents/DocumentsPanel.tsx`

For each document:
- Primary label: `doc.title || doc.filename`, show filename below if title exists
- Summary: truncated single line when status is "ready"
- Date: formatted (e.g., "Mar 15, 2024") next to file size
- Topics: small badges (`bg-primary/10 text-primary text-xs rounded-full px-2 py-0.5`)
- Pre-existing docs (null metadata) show filename only — no visual regression

---

## Implementation Order

```
Task 1 (Migration)       ─┐
Task 2 (Metadata service) ─┤── parallel, no deps
Task 4 (Pydantic model)   ─┤
Task 8 (TS types)         ─┘
         │
Task 3 (Ingestion)       ── depends on Tasks 1, 2
Task 5 (Retrieval)        ── depends on Task 1
         │
Task 6 (LLM/tools)        ── depends on Task 5
Task 7 (Chat router)      ── depends on Tasks 5, 6
         │
Task 9 (UI)               ── depends on Tasks 4, 8
```

---

## Critical Files

| File | Change |
|------|--------|
| `supabase/migrations/004_metadata_extraction.sql` | New migration |
| `app/backapp/frontend/app/services/metadata.py` | New — LLM extraction service |
| `app/backapp/frontend/app/services/ingestion.py` | Call extract_metadata, store results |
| `app/backapp/frontend/app/models/documents.py` | Add title, summary, topics, document_date |
| `app/backapp/frontend/app/services/retrieval.py` | Pass date/recency params to RPC |
| `app/backapp/frontend/app/services/llm.py` | Tool params, context format, RetrieveFn type |
| `app/backapp/frontend/app/routers/chat.py` | Forward kwargs in retrieve_fn closure |
| `app/frontend/src/types/index.ts` | Add metadata fields |
| `app/frontend/src/components/documents/DocumentsPanel.tsx` | Display metadata |

---

## Verification

1. Apply migration → confirm columns + updated `match_chunks` signature
2. Upload a `.txt` file with clear content and date references → wait for "ready"
3. Check DB: `SELECT title, summary, topics, document_date FROM documents` → populated
4. Check LangSmith for `extract_metadata` trace span
5. Chat with retrieval → context includes `(from: <title>)` and `[topics: ...]`
6. Ask a date-aware question → LLM uses `date_from`/`recency_weight` in tool call
7. Documents panel shows title, summary, topic badges, formatted date
8. Pre-existing docs (null metadata) display correctly with filename fallback
9. `npm run build` → no TS errors

## Unresolved Questions

1. **Does the local LLM support `response_format: {"type": "json_object"}`?** Fallback handles failure, but extraction quality degrades. May need to parse JSON from free-form response as middle ground.
2. **Will the local LLM reliably use optional tool parameters (`date_from`, `recency_weight`)?** If not, could apply a default recency_weight server-side instead.
